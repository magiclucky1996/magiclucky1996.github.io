<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>public blog of tianxiang</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="public blog of tianxiang">
<meta property="og:url" content="http://magiclucky1996.github.io/index.html">
<meta property="og:site_name" content="public blog of tianxiang">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="tianxiang">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="public blog of tianxiang" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">public blog of tianxiang</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://magiclucky1996.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-dublin适合远程办公的地点合集" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/04/25/dublin%E9%80%82%E5%90%88%E8%BF%9C%E7%A8%8B%E5%8A%9E%E5%85%AC%E7%9A%84%E5%9C%B0%E7%82%B9%E5%90%88%E9%9B%86/" class="article-date">
  <time class="dt-published" datetime="2023-04-25T09:30:16.880Z" itemprop="datePublished">2023-04-25</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="dublin适合远程办公的地点合集"><a href="#dublin适合远程办公的地点合集" class="headerlink" title="dublin适合远程办公的地点合集"></a>dublin适合远程办公的地点合集</h1><p>咖啡店晒晒太阳什么的，不知道，没有那么想在家待着，也不一定要一直去实验室，找个地方待着</p>
<ol>
<li>google search： places good for study outside with sunshine in dublin<ol>
<li><a target="_blank" rel="noopener" href="https://www.fordublinlovers.com/en/best/places-to-study-outdoors-in-dublin">https://www.fordublinlovers.com/en/best/places-to-study-outdoors-in-dublin</a></li>
<li><a target="_blank" rel="noopener" href="https://livstudent.com/7-study-spots-in-dublin-to-check-out/">https://livstudent.com/7-study-spots-in-dublin-to-check-out/</a></li>
<li><a target="_blank" rel="noopener" href="https://lovindublin.com/best-of/10-best-places-to-work-or-study-in-when-you-find-yourself-in-dublin-city-centre">https://lovindublin.com/best-of/10-best-places-to-work-or-study-in-when-you-find-yourself-in-dublin-city-centre</a></li>
<li><a target="_blank" rel="noopener" href="https://universitytimes.ie/2018/04/five-of-the-best-alternative-study-spaces/">https://universitytimes.ie/2018/04/five-of-the-best-alternative-study-spaces/</a></li>
</ol>
</li>
<li>Chatgpt,</li>
</ol>
<p>need wifi:</p>
<ol>
<li>Dublin City Libraries: Many libraries in Dublin have free Wi-Fi and offer a quiet environment to work in. Check with your local library for opening hours and availability.</li>
<li>The Bernard Shaw: This pub in Dublin has free Wi-Fi and plenty of tables to work at. It also has a garden area where you can enjoy the sunshine while you work.</li>
<li>The Fumbally: This cafe has free Wi-Fi and plenty of tables to work at. It’s a popular spot for freelancers and students in Dublin.</li>
<li>The Digital Hub: This is a co-working space in Dublin that offers Wi-Fi and desk space for a fee. It’s a great option if you need a more professional environment to work in.</li>
<li>Starbucks: Many Starbucks locations in Dublin offer free Wi-Fi, and they are a popular spot for studying or working remotely.</li>
<li>Costa Coffee: Similar to Starbucks, many Costa Coffee locations in Dublin also offer free Wi-Fi.</li>
</ol>
<p>no need wifi:</p>
<ol>
<li><p>Bewley’s Cafe: This cafe has several locations in Dublin and is known for its cozy atmosphere. It’s a great spot to grab a coffee or tea and enjoy a warm drink while people-watching.</p>
</li>
<li><p>The Pepper Pot Cafe: This is a quaint cafe located inside the Powerscourt Centre in Dublin. It’s a great spot to sit and relax with a book or chat with friends while enjoying a warm drink and some delicious food.</p>
</li>
<li><p>The Bald Barista: This cafe is a popular spot in Dublin for its cozy atmosphere and great coffee. It’s a great place to relax and enjoy some good company.</p>
</li>
<li><p>Brother Hubbard: This is another great cafe in Dublin that offers a cozy atmosphere and delicious food. It’s a popular spot for brunch, but you can also visit during the day to relax and unwind.</p>
</li>
<li><p>The Cake Cafe: This is a charming cafe located in a converted redbrick building in Dublin. It’s known for its homemade cakes and friendly atmosphere, making it a great spot to sit and chat with friends.</p>
</li>
<li><p>小红书</p>
</li>
</ol>
<p>2区星巴克</p>
<p>central library</p>
<p>han sung旁边的mind the step</p>
<p>dun laoghaire图书馆</p>
<p>blackrock library</p>
<p>google search library cafe等等</p>
<p>tcd exam hall</p>
<ol start="4">
<li><p>自己想到的</p>
<p>市中心教堂旁边的library</p>
<p>tcd学校里面</p>
<p>家里</p>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://magiclucky1996.github.io/2023/04/25/dublin%E9%80%82%E5%90%88%E8%BF%9C%E7%A8%8B%E5%8A%9E%E5%85%AC%E7%9A%84%E5%9C%B0%E7%82%B9%E5%90%88%E9%9B%86/" data-id="clgw2gsm50000g29f3kgy4arv" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-incoporate  mappo with sumo" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/04/25/incoporate%20%20mappo%20with%20sumo/" class="article-date">
  <time class="dt-published" datetime="2023-04-25T07:39:27.623Z" itemprop="datePublished">2023-04-25</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="incoporate-mappo-with-sumo"><a href="#incoporate-mappo-with-sumo" class="headerlink" title="incoporate  mappo with sumo"></a>incoporate  mappo with sumo</h1><h2 id="1-look-for-existing-mappo-sumo"><a href="#1-look-for-existing-mappo-sumo" class="headerlink" title="1. look for existing mappo + sumo"></a>1. look for existing mappo + sumo</h2><ul>
<li>reference</li>
</ul>
<ol>
<li>github</li>
<li>paper</li>
<li>resource of course era, presentation, tutorial (osint)</li>
</ol>
<ul>
<li>resources found</li>
</ul>
<p>github</p>
<ol>
<li><p>ppo + sumo <a target="_blank" rel="noopener" href="https://github.com/maxbren/Multi-Agent-Distributed-PPO-Traffc-light-control">https://github.com/maxbren/Multi-Agent-Distributed-PPO-Traffc-light-control</a></p>
</li>
<li><p>light mappo  <a target="_blank" rel="noopener" href="https://github.com/magiclucky1996/light_mappo">https://github.com/magiclucky1996/light_mappo</a> 基于这个写一下试试</p>
</li>
<li><p>q&#x2F;ac + sumo <a target="_blank" rel="noopener" href="https://github.com/magiclucky1996/deeprl_signal_control">https://github.com/magiclucky1996/deeprl_signal_control</a></p>
</li>
<li><p>mappo + mujoco <a target="_blank" rel="noopener" href="https://github.com/chauncygu/Multi-Agent-Constrained-Policy-Optimisation">https://github.com/chauncygu/Multi-Agent-Constrained-Policy-Optimisation</a></p>
</li>
<li><p>mappo&#x2F;qmix&#x2F;maddpg + mpe <a target="_blank" rel="noopener" href="https://github.com/Lizhi-sjtu/MARL-code-pytorch">https://github.com/Lizhi-sjtu/MARL-code-pytorch</a></p>
</li>
<li><p>ppo + sumo <a target="_blank" rel="noopener" href="https://github.com/YanivHacker/RLTrafficManager">https://github.com/YanivHacker/RLTrafficManager</a></p>
</li>
<li><p>noisy mappo+  <a target="_blank" rel="noopener" href="https://github.com/hijkzzz/noisy-mappo">https://github.com/hijkzzz/noisy-mappo</a></p>
</li>
</ol>
<p>papers</p>
<p><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/abstract/document/9549970/authors#authors">https://ieeexplore.ieee.org/abstract/document/9549970/authors#authors</a> 东北信息学院：提到了rl奖励稀疏的问题，然后他们给rl设计更多的reward 引导它学习。但是你怎么知道什么样的reward能够引导，这不是还是在reward function设计的范围里吗？</p>
<ul>
<li>insights<ol>
<li>sumo设计的问题，如果我们设一个控制周期之后的交通流状态为reward是不是不合理，怎么样去评价智能体schedule的好坏呢，怎么去评价智能体的action改善了交通呢，我是要搞交通呢，还是要搞rl呢，还是要搞啥，，，</li>
<li>上次会议的要点：1. insight可以给硕士做，但是要具体可行 2. 做一个oncoming 会议的scheduling(rl 多智能体 交通 计算机 人工智能) 3. sumo的模型可以封装好给本科生用 4.</li>
</ol>
</li>
<li>今天的计划（4.24）</li>
</ul>
<p>work 到12 点半，吃中饭，吃完中饭一点消化一会儿，回实验室一点半，回来继续work,work到两点多的时候睡午觉，五点跑路，去看看有没有吃的，不行就回家supervalu,晚上回家继续work一会儿，今天的弄完走之前deploy 和 push上去</p>
<ul>
<li>how other people implement marl training</li>
</ul>
<p>make contraction between these projects</p>
<p>分解成detailed steps</p>
<p>1.首先看下mappo的代码和deeprl sumo的代码以及ppo sumo代码（只做有必要做的事情）</p>
<ol start="2">
<li><p>做完1大概知道要干嘛，可以看看ppo trpo mappo</p>
</li>
<li><p>把每周4上午留作整理时间，所以我必须两天内搞定这个代码整定的事情，然后再用剩下的时间学习ppo trpo mappo，还要学sumo部分的东西，但是得非常快</p>
</li>
<li></li>
<li></li>
</ol>
<h2 id="2-make-it-with-materials-found"><a href="#2-make-it-with-materials-found" class="headerlink" title="2. make it with materials found"></a>2. make it with materials found</h2><p>生活的star：</p>
<p>琴</p>
<p>传统动画</p>
<p>breaking</p>
<p>网安</p>
<p>戒社交</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://magiclucky1996.github.io/2023/04/25/incoporate%20%20mappo%20with%20sumo/" data-id="clgw24ioh0000yc9f30vq1vyg" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-MARL implementation" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/04/25/MARL%20implementation/" class="article-date">
  <time class="dt-published" datetime="2023-04-25T07:39:27.623Z" itemprop="datePublished">2023-04-25</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="Part1-Codes-implementation-MARL"><a href="#Part1-Codes-implementation-MARL" class="headerlink" title="Part1: Codes implementation(MARL)"></a>Part1: Codes implementation(MARL)</h1><h2 id="1-Ubuntu-setting"><a href="#1-Ubuntu-setting" class="headerlink" title="1. Ubuntu setting"></a>1. Ubuntu setting</h2><h3 id="Install-oh-my-zsh"><a href="#Install-oh-my-zsh" class="headerlink" title="Install oh my zsh"></a>Install oh my zsh</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install zsh</span><br><span class="line">chsh -s $(<span class="built_in">which</span> zsh)</span><br><span class="line">sh -c <span class="string">&quot;<span class="subst">$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)</span>&quot;</span></span><br><span class="line"><span class="built_in">source</span> ~/.zshrc</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="setting-of-input-method-of-ubuntu"><a href="#setting-of-input-method-of-ubuntu" class="headerlink" title="setting of input method of ubuntu"></a>setting of input method of ubuntu</h3><p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/418042828">https://www.zhihu.com/question/418042828</a></p>
<h3 id="Install-nvidia-driver"><a href="#Install-nvidia-driver" class="headerlink" title="Install nvidia driver"></a>Install nvidia driver</h3><p>driver version : <code>470.63.01</code>.</p>
<p>CUDA version: CUDA Toolkit 11.4.</p>
<p>If your project is written with TensorFlow 1 and you need to use it with the newer versions of CUDA and NVIDIA driver that you have installed, you have a few options:</p>
<ol>
<li>Downgrade your NVIDIA driver and CUDA Toolkit versions to be compatible with TensorFlow 1. You can follow the installation instructions for TensorFlow 1.15.4 with GPU support, which requires CUDA Toolkit 10.0 or 10.1 and NVIDIA driver version 418.x or higher.</li>
<li>Use a virtual environment or container with the specific versions of CUDA Toolkit, NVIDIA driver, and TensorFlow 1 that your project requires. You can create a new virtual environment or container with the appropriate dependencies using tools like virtualenv or Docker.</li>
<li>Upgrade your project to use TensorFlow 2.x. Although there are some differences between TensorFlow 1 and TensorFlow 2, many of the core concepts and functionalities are similar, so the migration process may not be too difficult. You can use TensorFlow’s migration guide to help you with the process.</li>
</ol>
<p>​	</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo add-apt-repository ppa:graphics-drivers/ppa</span><br><span class="line">sudo apt update</span><br><span class="line">sudo apt install nvidia-driver-&lt;VERSION&gt;</span><br></pre></td></tr></table></figure>



<h3 id="meet-problem-with-unfigured-nvidia-driver"><a href="#meet-problem-with-unfigured-nvidia-driver" class="headerlink" title="meet problem with unfigured nvidia driver"></a>meet problem with unfigured nvidia driver</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">sudo apt-get remove --purge nvidia-dkms-470 nvidia-driver-470</span><br></pre></td></tr></table></figure>



<h3 id="still-doesn’t-work"><a href="#still-doesn’t-work" class="headerlink" title="still doesn’t work"></a>still doesn’t work</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">dpkg -l | grep -i nvidia</span><br><span class="line">sudo apt-get remove --purge <span class="string">&#x27;^nvidia-.*&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="Problem：-gpu-driver-gt-install-nvidia-driver470"><a href="#Problem：-gpu-driver-gt-install-nvidia-driver470" class="headerlink" title="Problem： gpu driver -&gt; install nvidia driver470"></a>Problem： gpu driver -&gt; install nvidia driver470</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">dpkg: error processing package nvidia-driver-470 (--configure):</span><br><span class="line"> dependency problems - leaving unconfigured</span><br><span class="line">No apport report written because the error message indicates its a followup error from a previous failure.</span><br><span class="line">                                                                                            Processing triggers <span class="keyword">for</span> desktop-file-utils (0.26-1ubuntu3) ...</span><br><span class="line">Processing triggers <span class="keyword">for</span> gnome-menus (3.36.0-1ubuntu3) ...</span><br><span class="line">Processing triggers <span class="keyword">for</span> libc-bin (2.35-0ubuntu3) ...</span><br><span class="line">Processing triggers <span class="keyword">for</span> man-db (2.10.2-1) ...</span><br><span class="line">Processing triggers <span class="keyword">for</span> mailcap (3.70+nmu1ubuntu1) ...</span><br><span class="line">Processing triggers <span class="keyword">for</span> initramfs-tools (0.140ubuntu13.1) ...</span><br><span class="line">update-initramfs: Generating /boot/initrd.img-5.19.0-38-generic</span><br><span class="line">Errors were encountered <span class="keyword">while</span> processing:</span><br><span class="line"> nvidia-dkms-470</span><br><span class="line"> nvidia-driver-470</span><br><span class="line">E: Sub-process /usr/bin/dpkg returned an error code (1)</span><br></pre></td></tr></table></figure>

<ul>
<li>solution: set in the software and update of ubuntu and reboot</li>
</ul>
<h3 id="Uninstall-old-Cuda"><a href="#Uninstall-old-Cuda" class="headerlink" title="Uninstall old Cuda"></a>Uninstall old Cuda</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/local/cuda/bin</span><br><span class="line">./cuda-uninstaller</span><br></pre></td></tr></table></figure>





<h3 id="Install-Cuda11-4"><a href="#Install-Cuda11-4" class="headerlink" title="Install Cuda11.4"></a>Install Cuda11.4</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget https://developer.download.nvidia.com/compute/cuda/11.4.3/local_installers/cuda_11.4.3_470.82.01_linux.run</span><br><span class="line"><span class="comment">## test the install of cuda</span></span><br><span class="line">nvcc --version</span><br></pre></td></tr></table></figure>



<h5 id="Install-cudnn"><a href="#Install-cudnn" class="headerlink" title="Install cudnn"></a>Install cudnn</h5><ul>
<li><a target="_blank" rel="noopener" href="https://developer.nvidia.com/cudnn">https://developer.nvidia.com/cudnn</a></li>
</ul>
<p>test the install of cudnn</p>
<hr>
<h2 id="2-MARL-env-setting"><a href="#2-MARL-env-setting" class="headerlink" title="2. MARL env setting"></a>2. MARL env setting</h2><h4 id="1-install-StarCraft-II-env"><a href="#1-install-StarCraft-II-env" class="headerlink" title="1. install StarCraft II env"></a>1. install StarCraft II env</h4><h5 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h5><ul>
<li><p><a target="_blank" rel="noopener" href="https://github.com/magiclucky1996/on-policy">https://github.com/magiclucky1996/on-policy</a></p>
<ul>
<li><code>unzip SC2.4.10.zip</code></li>
<li><code>echo &quot;export SC2PATH=~/StarCraftII/&quot; &gt; ~/.bashrc</code></li>
<li>download SMAC Maps, and move it to <code>~/StarCraftII/Maps/</code>.</li>
<li>To use a stableid, copy <code>stableid.json</code> from <a target="_blank" rel="noopener" href="https://github.com/Blizzard/s2client-proto.git">https://github.com/Blizzard/s2client-proto.git</a> to <code>~/StarCraftII/</code>.</li>
</ul>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/oxwhirl/smac">https://github.com/oxwhirl/smac</a></p>
<ul>
<li>Please use the Blizzard’s <a target="_blank" rel="noopener" href="https://github.com/Blizzard/s2client-proto#downloads">repository</a> to download the Linux version of StarCraft II. By default, the game is expected to be in <code>~/StarCraftII/</code> directory. This can be changed by setting the environment variable <code>SC2PATH</code>.</li>
</ul>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/oxwhirl/pymarl/blob/master/install_sc2.sh">https://github.com/oxwhirl/pymarl/blob/master/install_sc2.sh</a></p>
</li>
</ul>
<h5 id="Detailed-steps"><a href="#Detailed-steps" class="headerlink" title="Detailed steps"></a>Detailed steps</h5><ul>
<li>follow the instruction of shell script below</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># download and install starcraft ii</span><br><span class="line"></span><br><span class="line">wget http://blzdistsc2-a.akamaihd.net/Linux/SC2.4.10.zip</span><br><span class="line">unzip -P iagreetotheeula SC2.4.10.zip</span><br><span class="line"></span><br><span class="line"># download smac map</span><br><span class="line"></span><br><span class="line">MAP_DIR=&quot;$SC2PATH/Maps/&quot;</span><br><span class="line">wget https://github.com/oxwhirl/smac/releases/download/v0.1-beta1/SMAC_Maps.zip</span><br><span class="line">unzip SMAC_Maps.zip</span><br><span class="line">mv SMAC_Maps $MAP_DIR</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h5 id="Problem1-wandb-init"><a href="#Problem1-wandb-init" class="headerlink" title="Problem1  wandb.init"></a>Problem1  wandb.init</h5><pre><code>run = wandb.init(config=all_args,
                 project=all_args.env_name,
                 entity=all_args.user_name,
                 notes=socket.gethostname(),
                 name=str(all_args.algorithm_name) + &quot;_&quot; +
                      str(all_args.experiment_name) +
                      &quot;_seed&quot; + str(all_args.seed),
                 group=all_args.map_name,
                 dir=str(run_dir),
                 job_type=&quot;training&quot;,
                 reinit=True)
</code></pre>
<ul>
<li><p>these attributes</p>
<ul>
<li><p>project</p>
</li>
<li><p>env_name</p>
</li>
<li><p>entity</p>
</li>
<li><p>user_name</p>
</li>
<li><p>notes</p>
</li>
<li><p>name</p>
</li>
<li><p>gourp</p>
</li>
<li><p>dir</p>
</li>
</ul>
</li>
</ul>
<h5 id="Ideas"><a href="#Ideas" class="headerlink" title="Ideas"></a>Ideas</h5><ol>
<li><p>wandb permission denied: modify the wandb.init </p>
</li>
<li><p>python 10 is not compatible: switch to python 3.6 (comply with origin env as much as possible)</p>
</li>
<li><p>finsh the implementation of four marl project and get some figures.</p>
<ol>
<li>understand detail of each project</li>
</ol>
</li>
<li><p>finish my explorement of fundamental rl algorithms</p>
</li>
</ol>
<hr>
<h1 id="Part-2-Reading"><a href="#Part-2-Reading" class="headerlink" title="Part 2: Reading"></a>Part 2: Reading</h1><h2 id="Reference-1"><a href="#Reference-1" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><strong>spinning up</strong></li>
</ul>
<p><a target="_blank" rel="noopener" href="https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html">https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html</a> (there some recommendation of  reading here)</p>
<p><a target="_blank" rel="noopener" href="https://spinningup.openai.com/en/latest/spinningup/keypapers.html?highlight=rainbow">https://spinningup.openai.com/en/latest/spinningup/keypapers.html?highlight=rainbow</a> (key papers of rl)</p>
<p><a target="_blank" rel="noopener" href="https://spinningup.openai.com/en/latest/spinningup/keypapers.html?highlight=rainbow#model-free-rl">https://spinningup.openai.com/en/latest/spinningup/keypapers.html?highlight=rainbow#model-free-rl</a></p>
<ul>
<li><strong>github paper collection</strong></li>
</ul>
<p><a target="_blank" rel="noopener" href="https://github.com/LantaoYu/MARL-Papers">https://github.com/LantaoYu/MARL-Papers</a></p>
<h2 id="Papers"><a href="#Papers" class="headerlink" title="Papers"></a>Papers</h2><h3 id="1-Playing-Atari-with-Deep-Reinforcement-Learning"><a href="#1-Playing-Atari-with-Deep-Reinforcement-Learning" class="headerlink" title="1. Playing Atari with Deep Reinforcement Learning"></a>1. Playing Atari with Deep Reinforcement Learning</h3><p>为什么需要样本是独立的，独立同分布到底是什么意思</p>
<h3 id="2-Benchmarking-Multi-Agent-Deep-Reinforcement-Learning-Algorithms-in-Cooperative-Tasks"><a href="#2-Benchmarking-Multi-Agent-Deep-Reinforcement-Learning-Algorithms-in-Cooperative-Tasks" class="headerlink" title="2. Benchmarking Multi-Agent Deep Reinforcement Learning Algorithms in Cooperative Tasks"></a>2. Benchmarking Multi-Agent Deep Reinforcement Learning Algorithms in Cooperative Tasks</h3><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2006.07869">https://arxiv.org/abs/2006.07869</a></p>
<p><em>June 2020  ; Georgios Papoudakis ； Phd student, ；School of Informatics ； university of Edinburgh,</em></p>
<ul>
<li>experiment results serving as reference</li>
<li>insights regarding the effectiveness of different learning approaches</li>
<li>open-source algorithm codebase</li>
<li>open-source two rl envs</li>
</ul>
<h5 id="reading"><a href="#reading" class="headerlink" title="reading"></a>reading</h5><ul>
<li><p>algotithms</p>
<ul>
<li>independent<ul>
<li>iql</li>
<li>ia2c</li>
<li>ippo</li>
</ul>
</li>
<li>ctde<ul>
<li>ma ddpg</li>
<li>coma</li>
<li>ma ac</li>
<li>ma ppo</li>
</ul>
</li>
<li>value decompose<ul>
<li>vdn</li>
<li>qmix</li>
</ul>
</li>
</ul>
</li>
<li><p>envs</p>
<ul>
<li>Repeated Matrix Games</li>
<li>Multi-Agent Particle Environment(MPE)</li>
<li>StarCraft Multi-Agent Challenge</li>
<li>Level-Based Foraging(LBF)</li>
<li>Multi-Robot Warehouse</li>
</ul>
</li>
</ul>
<h5 id="some-thinking-in-the-reading"><a href="#some-thinking-in-the-reading" class="headerlink" title="some thinking in the reading"></a>some thinking in the reading</h5><ul>
<li><p>is there insights between different games? 不同类型的game有不同的特点</p>
</li>
<li><p>不同问题对joint action的需求不一样，这个要对问题的机理进行分析</p>
</li>
<li><p>运行时间：有的时候时间不一定花在算法的时间上，可能花在和环境交互的时间上，不同大小的模型，更新频率步长等也会影响算法时间，需要弄清楚算法时间相关影响变量。</p>
<ul>
<li>to be explored</li>
<li>if we used fixed algorithm, 随机性从哪里来，我能否限制随机性来对环境做比较。还是说我跑很多次，取平均值，来做比较。首先你得清楚整个训练的每个步骤和影响因素，所以要细读代码。（之后多攒一些问题可以专门地找人咨询）</li>
</ul>
</li>
<li><p>it could be interesting to try the chase and hide env</p>
</li>
<li><p>做成库给人用确实是很好的工具，我想做我自己的库，但是先看看有没有已有的（我先找点库跑一跑）</p>
</li>
<li><p>拿到其他智能体的模型可能很难直接从模型参数得到啥，但是可以输入看 模型输出的结果，（模型的结果，到环境的演化的概率分布）</p>
</li>
</ul>
<h5 id="conclusion-what-i-learn-from-this-passage"><a href="#conclusion-what-i-learn-from-this-passage" class="headerlink" title="conclusion(what i learn from this passage):"></a>conclusion(what i learn from this passage):</h5><p>- </p>
<h3 id=""><a href="#" class="headerlink" title=""></a></h3><h3 id="3-Rainbow-Combining-Improvements-in-Deep-Reinforcement-Learning"><a href="#3-Rainbow-Combining-Improvements-in-Deep-Reinforcement-Learning" class="headerlink" title="3. Rainbow: Combining Improvements in Deep Reinforcement Learning"></a>3. Rainbow: Combining Improvements in Deep Reinforcement Learning</h3><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1710.02298">https://arxiv.org/abs/1710.02298</a></p>
<p><em>Oct 2017</em></p>
<p><em>Matteo Hessel</em></p>
<p><em>Deepmind</em></p>
<h3 id="4-The-Surprising-Effectiveness-of-PPO-in-Cooperative-Multi-Agent-Games"><a href="#4-The-Surprising-Effectiveness-of-PPO-in-Cooperative-Multi-Agent-Games" class="headerlink" title="4. The Surprising Effectiveness of PPO in Cooperative Multi-Agent Games"></a>4. The Surprising Effectiveness of PPO in Cooperative Multi-Agent Games</h3><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2103.01955">https://arxiv.org/abs/2103.01955</a></p>
<p><em>Nov 2022</em></p>
<p><em>chao yu</em></p>
<h2 id="Books"><a href="#Books" class="headerlink" title="Books"></a>Books</h2><h3 id="1-RLbook-by-sutton"><a href="#1-RLbook-by-sutton" class="headerlink" title="1. RLbook by sutton\\"></a>1. RLbook by sutton\\</h3><h2 id="Videos"><a href="#Videos" class="headerlink" title="Videos"></a>Videos</h2><h3 id="1-Multi-Agent-Reinforcement-Learning-Part-I"><a href="#1-Multi-Agent-Reinforcement-Learning-Part-I" class="headerlink" title="1. Multi-Agent Reinforcement Learning (Part I)"></a>1. Multi-Agent Reinforcement Learning (Part I)</h3><p><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=RCu-nU4_TQM">https://www.youtube.com/watch?v=RCu-nU4_TQM</a></p>
<blockquote>
<p>simon institute; chi jin, princeton</p>
</blockquote>
<h3 id="2-Shusen-wang"><a href="#2-Shusen-wang" class="headerlink" title="2. Shusen wang"></a>2. Shusen wang</h3><h1 id="Part-3-Questions"><a href="#Part-3-Questions" class="headerlink" title="Part 3: Questions"></a>Part 3: Questions</h1><h2 id="1-why-data-needs-to-be-IId"><a href="#1-why-data-needs-to-be-IId" class="headerlink" title="1. why data needs to be IId?"></a>1. why data needs to be IId?</h2><blockquote>
<p>可以参考分布式机器学习的一些东西，（我一直在做分布式，分布式机器学习，分布式存储）</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=STxtRucv_zo&t=1504s">https://www.youtube.com/watch?v=STxtRucv_zo&amp;t=1504s</a></p>
<p>1&#x2F; 具有相同的概率分布：分布没有波动</p>
<p>2&#x2F; 相互独立：了解一个变量的值不会提供另外一个变量的信息</p>
<h5 id="Example-1-edit"><a href="#Example-1-edit" class="headerlink" title="Example 1[edit]"></a>Example 1[<a target="_blank" rel="noopener" href="https://en.wikipedia.org/w/index.php?title=Independent_and_identically_distributed_random_variables&action=edit&section=8">edit</a>]</h5><p>A sequence of outcomes of spins of a fair or unfair <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Roulette">roulette</a> wheel is i.i.d. One implication of this is that if the roulette ball lands on “red”, for example, 20 times in a row, the next spin is no more or less likely to be “black” than on any other spin (see the <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Gambler's_fallacy">Gambler’s fallacy</a>).</p>
<p>A sequence of fair or loaded dice rolls is i.i.d.</p>
<p>A sequence of fair or unfair coin flips is i.i.d.</p>
<p>In <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Signal_processing">signal processing</a> and <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Image_processing">image processing</a> the notion of transformation to i.i.d. implies two specifications, the “i.d.”part and the “i.” part:</p>
<p>(i.d.) the signal level must be balanced on the time axis;</p>
<p>(i.) the signal spectrum must be flattened, i.e. transformed by filtering (such as <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Deconvolution">deconvolution</a>) to a <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/White_noise">white noise</a> signal (i.e. a signal where all frequencies are equally present).</p>
<h5 id="Example-2-edit"><a href="#Example-2-edit" class="headerlink" title="Example 2[edit]"></a>Example 2[<a target="_blank" rel="noopener" href="https://en.wikipedia.org/w/index.php?title=Independent_and_identically_distributed_random_variables&action=edit&section=9">edit</a>]</h5><p>Toss a coin 10 times and record how many times does the coin lands on head.</p>
<ol>
<li>Independent – each outcome of landing will not affect the other outcome, which means the 10 results are independent from each other.</li>
<li>Identically Distributed – if the coin is a homogeneous material, each time the probability for head is 0.5, which means the probability is identical for each time.</li>
</ol>
<h5 id="Example-3-edit"><a href="#Example-3-edit" class="headerlink" title="Example 3[edit]"></a>Example 3[<a target="_blank" rel="noopener" href="https://en.wikipedia.org/w/index.php?title=Independent_and_identically_distributed_random_variables&action=edit&section=10">edit</a>]</h5><p>Roll a dice 10 times and record how many time the result is 1.</p>
<ol>
<li>Independent – each outcome of the dice will not affect the next one, which means the 10 results are independent from each other.</li>
<li>Identically Distributed – if the dice is a homogeneous material, each time the probability for the number 1 is 1&#x2F;6, which means the probability is identical for each time.</li>
</ol>
<h5 id="Example-4-edit"><a href="#Example-4-edit" class="headerlink" title="Example 4[edit]"></a>Example 4[<a target="_blank" rel="noopener" href="https://en.wikipedia.org/w/index.php?title=Independent_and_identically_distributed_random_variables&action=edit&section=11">edit</a>]</h5><p>Choose a card from a standard deck of cards containing 52 cards, then place the card back in the deck. Repeat it for 52 times. Record the number of King appears</p>
<ol>
<li>Independent – each outcome of the card will not affect the next one, which means the 52 results are independent from each other.</li>
<li>Identically Distributed – after drawing one card from it, each time the probability for King is 4&#x2F;52, which means the probability is identical for each time.</li>
</ol>
<h2 id="2-why-machine-learning-need-IID"><a href="#2-why-machine-learning-need-IID" class="headerlink" title="2. why machine learning need IID?"></a>2. why machine learning need IID?</h2><p>Machine learning uses currently acquired massive quantities of data to deliver faster, more accurate results.[<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables#cite_note-7">7]</a> Therefore, we need to use historical data with overall representativeness. If the data obtained is not representative of the overall situation, then the rules will be summarized badly or wrongly.</p>
<p>Through i.i.d. hypothesis, the number of individual cases in the training sample can be greatly reduced.</p>
<p>This assumption makes maximization very easy to calculate mathematically. Observing the assumption of independent and identical distribution in mathematics simplifies the calculation of the likelihood function in optimization problems. Because of the assumption of independence, the likelihood function can be written like this</p>
<p>In order to maximize the probability of the observed event, take the log function and maximize the parameter <em>θ</em>. </p>
<p>The computer is very efficient to calculate multiple additions, but it is not efficient to calculate the multiplication. This simplification is the core reason for the increase in computational efficiency. And this Log transformation is also in the process of maximizing, turning many exponential functions into linear functions.</p>
<p>For two reasons, this hypothesis is easy to use the central limit theorem in practical applications.</p>
<ol>
<li>Even if the sample comes from a more complex non-Gaussian distribution, it can also approximate well. Because it can be simplified from the central limit theorem to Gaussian distribution. For a large number of observable samples, “the sum of many random variables will have an approximately normal distribution”.</li>
<li>The second reason is that the accuracy of the model depends on the simplicity and representative power of the model unit, as well as the data quality. Because the simplicity of the unit makes it easy to interpret and scale, and the representative power + scale out of the unit improves the model accuracy. Like in a deep neural network, each neuron is very simple but has strong representative power, layer by layer to represent more complex features to improve model accuracy.</li>
</ol>
<p>some user has photo full of animals, some user has photo full of views</p>
<p>iid：</p>
<p>Independent and identically distributed: the data is uniform, randomly disrupted, and the statistics of each node are similar (mean, variance)</p>
<p>If the data is disrupted, shuffle, the data becomes independent and identically distributed, which is equivalent to a node, a distribution within a set</p>
<p>The statistical nature of each mobile phone user’s data is different. Some people like to take pictures of landscapes, while others like to take selfies.</p>
<p>My understanding: to prevent crooked data science? Go up the hill evenly, don’t click left and right?</p>
<h2 id="3-why-Experience-replay"><a href="#3-why-Experience-replay" class="headerlink" title="3. why Experience replay"></a>3. why Experience replay</h2><blockquote>
<p><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=rhslMPmj7SY&list=RDCMUC9qKcEgXHPFP2-ywYoA-E0Q&index=6">https://www.youtube.com/watch?v=rhslMPmj7SY&amp;list=RDCMUC9qKcEgXHPFP2-ywYoA-E0Q&amp;index=6</a></p>
</blockquote>
<h2 id="4-the-reuse-of-experience-in-experience-replay"><a href="#4-the-reuse-of-experience-in-experience-replay" class="headerlink" title="4. the reuse of experience in experience replay"></a>4. the reuse of experience in experience replay</h2><p>first thing: how is transition used?</p>
<p>each experience is a sampling of the real world,</p>
<p>if we want to reuse it , why not </p>
<h2 id="5-what-is-sampling-efficiency-in-rl"><a href="#5-what-is-sampling-efficiency-in-rl" class="headerlink" title="5. what is sampling efficiency in rl?"></a>5. what is sampling efficiency in rl?</h2><p>what is meaning of sampling efficiency：</p>
<p>sampling efficiency：</p>
<p>unbalance load, the amount of some user’s data is large, others are small so that some node has iterated hundreds of time, some just one time</p>
<h2 id="5-Q-learning-take-Td-error-as-loss-func-how-about-AC-and-PG"><a href="#5-Q-learning-take-Td-error-as-loss-func-how-about-AC-and-PG" class="headerlink" title="5. Q-learning take Td-error  as loss func, how about AC and PG?"></a>5. Q-learning take Td-error  as loss func, how about AC and PG?</h2><ul>
<li><strong>this is the leaning of td</strong></li>
</ul>
<p><img src="https://raw.githubusercontent.com/magiclucky1996/picgo/main/test/image-20230418164141297.png" alt="image-20230418164141297"></p>
<ul>
<li><strong>Policy Gradient</strong></li>
</ul>
<p>Policy gradient：Instead of minimizing TD error, it maximizes V, maximizes V, directly calculates the derivative of the model parameters on A, and then performs gradient ascent to update the model parameters to maximize V,</p>
<ul>
<li>the update of policy in <em>Policy Gradient</em>*</li>
</ul>
<p><img src="https://raw.githubusercontent.com/magiclucky1996/picgo/main/test/image-20230418163835203.png" alt="image-20230418163835203"></p>
<ul>
<li>while the v is equal to :</li>
</ul>
<p><img src="https://raw.githubusercontent.com/magiclucky1996/picgo/main/image-20230420102406349.png" alt="image-20230420102406349"></p>
<ul>
<li>then calculate the derivative</li>
</ul>
<p><img src="https://raw.githubusercontent.com/magiclucky1996/picgo/main/image-20230420102508795.png" alt="image-20230420102508795"></p>
<ul>
<li>use chain rule to calculate form 2</li>
</ul>
<p><img src="https://raw.githubusercontent.com/magiclucky1996/picgo/main/image-20230420102536383.png" alt="image-20230420102536383"></p>
<ul>
<li>so the result is :</li>
</ul>
<p><img src="https://raw.githubusercontent.com/magiclucky1996/picgo/main/test/image-20230418163957262.png" alt="image-20230418163957262"></p>
<ul>
<li><p>for form 1 : at each state, summation over all actions, could also be replaced with MC </p>
</li>
<li><p>for form 2: Hard to calculate expectation, use MC instead</p>
</li>
<li></li>
<li><p><strong>overview of the algorithm</strong></p>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/magiclucky1996/picgo/main/test/image-20230418174000255.png" alt="image-20230418174000255"></p>
<p><strong>questions</strong></p>
<ul>
<li><p>Question1: if use form 1: how to scan over all actions?</p>
</li>
<li><p>Question2: if use form 2: how to guarantee adequate sampling?</p>
</li>
</ul>
<h2 id="6-how-about-sampling-multiple-actions-and-update-the-model-at-the-same-state-like-we-do-enough-sampling-at-the-same-state-in-multi-armed-bandit"><a href="#6-how-about-sampling-multiple-actions-and-update-the-model-at-the-same-state-like-we-do-enough-sampling-at-the-same-state-in-multi-armed-bandit" class="headerlink" title="6. how about sampling multiple actions and update the model at the same state?(like we do enough sampling at the same state in multi-armed bandit"></a>6. how about sampling multiple actions and update the model at the same state?(like we do enough sampling at the same state in multi-armed bandit</h2><p>because of the independence of data?</p>
<p>we know that related data and data with same distribution is harmful  </p>
<h2 id="7-how-to-Design-traffic-control-problem"><a href="#7-how-to-Design-traffic-control-problem" class="headerlink" title="7. how to  Design traffic control problem"></a>7. how to  Design traffic control problem</h2><p>fully-observed:</p>
<ol>
<li>the action of other agents <ol>
<li>how to utilize the action of other agent</li>
</ol>
</li>
<li>the strategy of other agents </li>
<li>how to utilized the strategy of other agents: prediction</li>
<li>the state of other agents</li>
</ol>
<p>the design of global reward function</p>
<p>the design of action in different levels of traffic</p>
<p>the source of random: random form the strategy; random from the state transferring of the env</p>
<hr>
<h1 id="Part4-projects"><a href="#Part4-projects" class="headerlink" title="Part4: projects"></a>Part4: projects</h1><h1 id="Project1-Mappo-official-implementation"><a href="#Project1-Mappo-official-implementation" class="headerlink" title="Project1: Mappo official implementation"></a>Project1: Mappo official implementation</h1><p><a target="_blank" rel="noopener" href="https://github.com/magiclucky1996/on-policy">https://github.com/magiclucky1996/on-policy</a></p>
<h4 id="paper-reading"><a href="#paper-reading" class="headerlink" title="paper reading"></a>paper reading</h4><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2103.01955">https://arxiv.org/abs/2103.01955</a></p>
<h3 id="-1"><a href="#-1" class="headerlink" title=""></a></h3><h4 id="bugs-when-running"><a href="#bugs-when-running" class="headerlink" title="bugs when running"></a>bugs when running</h4><ul>
<li>RuntimeError: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling <code>cublasSgemm( handle, opa, opb, m, n, k, &amp;alpha, a, lda, b, ldb, &amp;beta, c, ldc)</code></li>
</ul>
<h3 id="running"><a href="#running" class="headerlink" title="running"></a>running</h3><ul>
<li>first running</li>
</ul>
<hr>
<h1 id="Project2-light-mappo"><a href="#Project2-light-mappo" class="headerlink" title="Project2: light mappo"></a>Project2: light mappo</h1><p><a target="_blank" rel="noopener" href="https://github.com/magiclucky1996/light_mappo">https://github.com/magiclucky1996/light_mappo</a></p>
<hr>
<h1 id="Project-3-Marl-sumo"><a href="#Project-3-Marl-sumo" class="headerlink" title="Project 3: Marl-sumo"></a>Project 3: Marl-sumo</h1><p><a target="_blank" rel="noopener" href="https://github.com/magiclucky1996/deeprl_signal_control">https://github.com/magiclucky1996/deeprl_signal_control</a></p>
<h3 id="install-sumo"><a href="#install-sumo" class="headerlink" title="install sumo"></a>install sumo</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo add-apt-repository ppa:sumo/stable</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install sumo sumo-tools sumo-doc</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<h4 id="Problem1-with-sumo-cannot-find-local-schema"><a href="#Problem1-with-sumo-cannot-find-local-schema" class="headerlink" title="Problem1: with sumo cannot find local schema"></a>Problem1: with sumo cannot find local schema</h4><ul>
<li>warning</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Warning: Cannot <span class="built_in">read</span> <span class="built_in">local</span> schema <span class="string">&#x27;/usr/share/sumo/bin/data/xsd/additional_file.xsd&#x27;</span>, will try website lookup.</span><br><span class="line">Warning: Cannot <span class="built_in">read</span> <span class="built_in">local</span> schema <span class="string">&#x27;/usr/share/sumo/bin/data/xsd/routes_file.xsd&#x27;</span>, will try website lookup.</span><br><span class="line">Warning: Cannot <span class="built_in">read</span> <span class="built_in">local</span> schema <span class="string">&#x27;/usr/share/sumo/bin/data/xsd/net_file.xsd&#x27;</span>, will try website lookup.</span><br></pre></td></tr></table></figure>

<ul>
<li>solution</li>
</ul>
<p>change sumo version:turn to sumo 1.16, </p>
<h4 id="Problem2-not-using-gpu"><a href="#Problem2-not-using-gpu" class="headerlink" title="Problem2: not using gpu"></a>Problem2: not using gpu</h4><ul>
<li>solution</li>
</ul>
<p>reinstall all the staff related to gpu</p>
<p>after install driver, cuda, if they are set the right env variable?: this may cause not working, so now im running with cpu, i show reinstall and do a test.</p>
<h4 id="Problem-3-Code-is-written-in-tensorflow-1-but-gpu-only-support-tensorflow-2"><a href="#Problem-3-Code-is-written-in-tensorflow-1-but-gpu-only-support-tensorflow-2" class="headerlink" title="Problem 3:  Code is written in tensorflow 1 but gpu only support tensorflow  2"></a>Problem 3:  Code is written in tensorflow 1 but gpu only support tensorflow  2</h4><ol>
<li>modify the code</li>
</ol>
<p>Replace all <code>import tensorflow as tf</code> statements with <code>import tensorflow.compat.v1 as tf</code> followed by <code>tf.disable_v2_behavior()</code>.</p>
<p>Replace all deprecated TensorFlow 1.x syntax with TensorFlow 2.x syntax. This includes changes to <code>tf.Session()</code> to <code>tf.compat.v1.Session()</code>, <code>tf.global_variables_initializer()</code> to <code>tf.compat.v1.global_variables_initializer()</code>, and so on.</p>
<p>Replace <code>tf.contrib</code> modules with equivalent modules in <code>tf.keras</code> or other TensorFlow 2.x modules. For example, <code>tf.contrib.layers</code> can be replaced with <code>tf.keras.layers</code>.</p>
<ol start="2">
<li>migrate following the official instruction</li>
</ol>
<p><a target="_blank" rel="noopener" href="https://www.tensorflow.org/guide/migrate">https://www.tensorflow.org/guide/migrate</a></p>
<h4 id="Problem4-set-the-growth-of-gpu"><a href="#Problem4-set-the-growth-of-gpu" class="headerlink" title="Problem4: set the growth of gpu"></a>Problem4: set the growth of gpu</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">config = tf.ConfigProto()</span><br><span class="line">config.gpu_options.allow_growth=<span class="literal">True</span></span><br><span class="line">sess = tf.Session(config=config)</span><br></pre></td></tr></table></figure>









<h2 id="MARL-SUMO-Modeling"><a href="#MARL-SUMO-Modeling" class="headerlink" title="MARL-SUMO Modeling"></a>MARL-SUMO Modeling</h2><h3 id="Problem-definition"><a href="#Problem-definition" class="headerlink" title="Problem definition"></a>Problem definition</h3><h3 id="Markov-decision-process-modeling"><a href="#Markov-decision-process-modeling" class="headerlink" title="Markov decision process modeling"></a>Markov decision process modeling</h3><h3 id="System-informations"><a href="#System-informations" class="headerlink" title="System informations"></a>System informations</h3><figure class="highlight as"><figcaption><span>sdf</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">system: ubuntu <span class="number">22.04</span> LTS</span><br><span class="line">python: <span class="number">3.8</span></span><br><span class="line">gpu: gtx <span class="number">3060</span> laptop version</span><br><span class="line">cuda: <span class="number">11.3</span></span><br><span class="line">cudnn: version correspongding to cuda version</span><br><span class="line">SUMO: <span class="number">1.16</span></span><br><span class="line">tensorflow: tensorflow-gpu <span class="number">1.14</span></span><br></pre></td></tr></table></figure>



<h3 id="bugs-and-problems"><a href="#bugs-and-problems" class="headerlink" title="bugs and problems"></a>bugs and problems</h3><h2 id="Training-record"><a href="#Training-record" class="headerlink" title="Training record"></a>Training record</h2><h5 id="Q-leaning-with-16-intersections"><a href="#Q-leaning-with-16-intersections" class="headerlink" title="Q-leaning with 16 intersections"></a>Q-leaning with 16 intersections</h5><ol>
<li>0413 morning</li>
</ol>
<ul>
<li>hyperparameter</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">gamma = 0.99</span><br><span class="line">lr_init = 1e-4</span><br><span class="line">lr_decay = constant</span><br><span class="line">epsilon_init = 1.0</span><br><span class="line">epsilon_min = 0.01</span><br><span class="line">epsilon_decay = linear</span><br><span class="line">epsilon_ratio = 0.5</span><br><span class="line">num_fc = 128</span><br><span class="line">num_h = 64</span><br><span class="line">batch_size = 20</span><br><span class="line">buffer_size = 1000</span><br><span class="line">reward_norm = 3000.0</span><br><span class="line">reward_clip = 2.0</span><br></pre></td></tr></table></figure>

<ul>
<li><p>experiment time:  13h</p>
</li>
<li><p>experiment result:</p>
</li>
</ul>
<h5 id="-2"><a href="#-2" class="headerlink" title=""></a><img src="https://raw.githubusercontent.com/magiclucky1996/picgo/main/test/iqld.png" alt="iqld"></h5><ol>
<li>0413 morning</li>
</ol>
<ul>
<li><p>hyperparater</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[MODEL_CONFIG]</span><br><span class="line">rmsp_alpha = 0.99</span><br><span class="line">rmsp_epsilon = 1e-5</span><br><span class="line">max_grad_norm = 40</span><br><span class="line">gamma = 0.99</span><br><span class="line">lr_init = 5e-4</span><br><span class="line">lr_decay = constant</span><br><span class="line">entropy_coef_init = 0.01</span><br><span class="line">entropy_coef_min = 0.01</span><br><span class="line">entropy_decay = constant</span><br><span class="line">entropy_ratio = 0.5</span><br><span class="line">value_coef = 0.5</span><br><span class="line">num_fw = 128</span><br><span class="line">num_ft = 32</span><br><span class="line">num_lstm = 64</span><br><span class="line">num_fp = 64</span><br><span class="line">batch_size = 120</span><br><span class="line">reward_norm = 2000.0</span><br><span class="line">reward_clip = 2.0</span><br></pre></td></tr></table></figure>
</li>
<li><p>result</p>
<p><img src="https://raw.githubusercontent.com/magiclucky1996/picgo/main/test/ac413.png" alt="ac413"></p>
</li>
<li><p>sac run before</p>
<p><img src="https://raw.githubusercontent.com/magiclucky1996/picgo/main/test/ac.png" alt="ac"></p>
</li>
</ul>
<h1 id="Project-4-General-marl"><a href="#Project-4-General-marl" class="headerlink" title="Project 4: General marl"></a>Project 4: General marl</h1><p><a target="_blank" rel="noopener" href="https://github.com/magiclucky1996/MARL-code-pytorch">https://github.com/magiclucky1996/MARL-code-pytorch</a></p>
<hr>
<h1 id="Part-5-what’s-next"><a href="#Part-5-what’s-next" class="headerlink" title="Part 5: what’s next?"></a>Part 5: what’s next?</h1><h2 id="1-what’s-next-Incorporate-Mappo-into-sumo-simulation"><a href="#1-what’s-next-Incorporate-Mappo-into-sumo-simulation" class="headerlink" title="1. what’s next? Incorporate Mappo into sumo simulation"></a>1. what’s next? Incorporate Mappo into sumo simulation</h2><ul>
<li>actually this is similar to what we do two years ago, combine sac with sumo simulation</li>
<li>but this time, dive deeper into problem definition, modeling, network , rl learning algorithm part.</li>
</ul>
<h2 id="2-what’s-next-go-through-rl-basics"><a href="#2-what’s-next-go-through-rl-basics" class="headerlink" title="2. what’s next? go through rl basics"></a>2. what’s next? go through rl basics</h2><h2 id="3-what’s-next-go-through-markov-modeling"><a href="#3-what’s-next-go-through-markov-modeling" class="headerlink" title="3. what’s next? go through markov modeling"></a>3. what’s next? go through markov modeling</h2><h2 id="4-what’s-next-go-through-urban-traffic-modeling-and-control"><a href="#4-what’s-next-go-through-urban-traffic-modeling-and-control" class="headerlink" title="4. what’s next? go through urban traffic modeling and control"></a>4. what’s next? go through urban traffic modeling and control</h2><p>每次只能解决一个问题，按重要度进行排序，我已经看够了各种理论，今天重要的是找几个算法和几个环境玩一玩，玩玩不同的环境，找出环境之间的feature，得到一些insights</p>
<p>然后把ppo理解，看懂mappo，跑起来mappo</p>
<p>明天重点就是交通环境的建模，明天晚上要弄出周四meeting的东西</p>
<p>rl-training： general view</p>
<ol>
<li>环境初始化，得到一个初始状态（每次都一样对不对，这个初始出发的学习路线可能会不一样，）</li>
<li>我从初始状态出发，开始我的旅行，我在单个状态是通过trail and error进行学习，我在打游戏的时候可以从一个节点重来，但可惜的是现实生活不行，但如果我们把它做成游戏一样不是很好嘛，比如在交通信号灯问题里，，一个状态的试错学习，多试试遥杆，其实控制也是，因为我们没法计算，但是我们可以计算和感觉相结合。连续单状态地更新模型有什么好处？不知道，</li>
</ol>
<h2 id="5-play-with-envs-different-envs-and-different-libs"><a href="#5-play-with-envs-different-envs-and-different-libs" class="headerlink" title="5. play with envs(different envs and different libs)"></a>5. play with envs(different envs and different libs)</h2><hr>
<h1 id="Part6-Additional-information"><a href="#Part6-Additional-information" class="headerlink" title="Part6 : Additional information"></a>Part6 : Additional information</h1><h2 id="1-Deploy-blog-with-hexo-typora-github-and-picgo"><a href="#1-Deploy-blog-with-hexo-typora-github-and-picgo" class="headerlink" title="1. Deploy blog with hexo, typora,github and picgo"></a>1. Deploy blog with hexo, typora,github and picgo</h2><ul>
<li>install nodejs</li>
<li>install hexo</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install -g hexo-cli</span><br></pre></td></tr></table></figure>

<ul>
<li>create a blog</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo init my-blog</span><br></pre></td></tr></table></figure>

<ul>
<li>change to this blog</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> my-blog	</span><br></pre></td></tr></table></figure>

<ul>
<li>install dependence</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install</span><br></pre></td></tr></table></figure>

<ul>
<li>install hexo deployer</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-deployer --save</span><br></pre></td></tr></table></figure>

<ul>
<li>modify the _config.yml</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">url:</span> <span class="string">https://&lt;your</span> <span class="string">github</span> <span class="string">user</span> <span class="string">name&gt;.github.io/</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="attr">deploy:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">git</span></span><br><span class="line">  <span class="attr">repository:</span> <span class="string">git@github.com:username/username.github.io.git</span></span><br><span class="line">  <span class="attr">branch:</span> <span class="string">master</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>link local git with github so that you can push local file to github</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t ed25519 -C <span class="string">&quot;your_email@example.com&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">cat</span> ~/.ssh/id_ed25519.pub</span><br></pre></td></tr></table></figure>

<ul>
<li>copy this pub key to your github account: settings -&gt; ssh and gpg keys</li>
<li>write your blogs in format of .md and add it to …&#x2F;hexo&#x2F;my-blog&#x2F;source&#x2F;_posts</li>
<li>use hexo generate to generate html files</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo generate</span><br></pre></td></tr></table></figure>

<ul>
<li>use hexo server to view locally</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo server</span><br></pre></td></tr></table></figure>

<ul>
<li>use hexo deploy to deploy to github</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo deploy</span><br></pre></td></tr></table></figure>





<h2 id="2-Version-control-for-blog-source-with-multiple-devices-by-git-and-github"><a href="#2-Version-control-for-blog-source-with-multiple-devices-by-git-and-github" class="headerlink" title="2. Version control for blog source with multiple devices by git and github"></a>2. Version control for blog source with multiple devices by git and github</h2><ul>
<li>on one computer</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/hexo/my-blog/source/_posts</span><br><span class="line">git init</span><br><span class="line">git add .</span><br><span class="line">git commit -m <span class="string">&quot;first commit on linux&quot;</span></span><br><span class="line">git remote add origin &lt;<span class="built_in">link</span> of github repo&gt;</span><br><span class="line">git push -u origin main</span><br></pre></td></tr></table></figure>

<ul>
<li>on another computer</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/hexo/my-blog/source</span><br><span class="line">git <span class="built_in">clone</span> &lt;<span class="built_in">link</span> of github repo&gt;</span><br><span class="line">git pull origin main <span class="comment"># pull from remote repo</span></span><br><span class="line">git push -u origin main <span class="comment"># pull to the remote repo</span></span><br></pre></td></tr></table></figure>



<h2 id="3-Image-uploader-Picgo-and-typora"><a href="#3-Image-uploader-Picgo-and-typora" class="headerlink" title="3. Image uploader: Picgo and typora"></a>3. Image uploader: Picgo and typora</h2><h5 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h5><ul>
<li><p><a target="_blank" rel="noopener" href="https://support.typora.io/Upload-Image/">https://support.typora.io/Upload-Image/</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://picgo.github.io/PicGo-Core-Doc/zh/guide/config.html#%E9%BB%98%E8%AE%A4%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6">https://picgo.github.io/PicGo-Core-Doc/zh/guide/config.html#%E9%BB%98%E8%AE%A4%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6</a></p>
</li>
</ul>
<h5 id="Detailed-steps-1"><a href="#Detailed-steps-1" class="headerlink" title="Detailed steps"></a>Detailed steps</h5><ul>
<li>in typora<ul>
<li>click file -&gt; preference -&gt; image: choose download to install picgo-core</li>
</ul>
</li>
<li><code>picgo set uploader</code></li>
<li><code>picgo use uploader</code></li>
<li>you can set automatically upload photo in typora -&gt; preference -&gt; image</li>
<li>it’s done! enjoy!</li>
</ul>
<p>tips:</p>
<p>we don’t need to run it by ourselves if the graph run by others is enough for our need.</p>
<p>last hour for the modeling of marl env</p>
<p>if have a goal or a question to figure, it will motivate , so seperate it into some detailed small questions, and motivate urself, so there will be postive feedback from exploring.</p>
<p>basic ideas of rl -&gt; ppo -&gt; mappo , …</p>
<p>stably read some papers and incorprate into it</p>
<h1 id="MARL-modeling"><a href="#MARL-modeling" class="headerlink" title="MARL modeling"></a>MARL modeling</h1><h2 id="traffic-control-ma2c"><a href="#traffic-control-ma2c" class="headerlink" title="traffic control + ma2c"></a>traffic control + ma2c</h2><ul>
<li>problem definition</li>
</ul>
<p>		</p>
<p><img src="https://raw.githubusercontent.com/magiclucky1996/picgo/main/image-20230420114007282.png" alt="image-20230420114007282"></p>
<ul>
<li>state space</li>
</ul>
<p><img src="https://raw.githubusercontent.com/magiclucky1996/picgo/main/image-20230420111112341.png" alt="image-20230420111112341"></p>
<ul>
<li><p>action space</p>
<ul>
<li><h2 id="phase-switch"><a href="#phase-switch" class="headerlink" title="phase switch"></a>phase switch</h2></li>
<li><p>phase duration</p>
<ul>
<li>make decision for how long the phase last</li>
</ul>
</li>
<li><p>phase itself</p>
<ul>
<li>fixed control period</li>
</ul>
</li>
</ul>
</li>
<li><p>reward function</p>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/magiclucky1996/picgo/main/image-20230420111340901.png" alt="image-20230420111340901"></p>
<ul>
<li>training algorithm</li>
</ul>
<h2 id="SMAC-mappo"><a href="#SMAC-mappo" class="headerlink" title="SMAC + mappo"></a>SMAC + mappo</h2><h1 id="Rl-algorithm"><a href="#Rl-algorithm" class="headerlink" title="Rl algorithm"></a>Rl algorithm</h1><h2 id="trpo"><a href="#trpo" class="headerlink" title="trpo"></a>trpo</h2><ul>
<li>general view</li>
</ul>
<p>In order to solve the problem of  leaning rate being too big, the cost function is approximated in trust region, and then the optimal value is calculated </p>
<ul>
<li><p>persudo code</p>
</li>
<li><p>code</p>
</li>
</ul>
<h2 id="ppo"><a href="#ppo" class="headerlink" title="ppo"></a>ppo</h2><ul>
<li>general view</li>
<li>persudo code</li>
<li>code</li>
</ul>
<h2 id="mappo"><a href="#mappo" class="headerlink" title="mappo"></a>mappo</h2><ul>
<li>general view</li>
<li>persudo code</li>
<li>code</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://magiclucky1996.github.io/2023/04/25/MARL%20implementation/" data-id="clgw24ion0001yc9fd4ox3loo" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-insights" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/04/25/insights/" class="article-date">
  <time class="dt-published" datetime="2023-04-25T07:39:27.623Z" itemprop="datePublished">2023-04-25</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="insights"><a href="#insights" class="headerlink" title="insights"></a>insights</h1><p><strong>td error 先不更新，把式子放在那里，等到达最后再更新。把已探究出来的列着，等到回合结束再更新。</strong></p>
<p><strong>argmax为什么不好？为什么actor比argmax更好？为什么ac就比q learning好？</strong></p>
<p><strong>为什么不能一开始就疯狂探索，100%，反正我可以不用管当前的性能？</strong></p>
<ul>
<li>我可以一开始就疯狂探索，然后把状态转移的r放在那里放着，</li>
<li>gym的rl环境不够准确，我觉得不同的环境千差万别。。没法体现rl算法的效率。这些人也许并没有多高明。</li>
</ul>
<p>This approach is called pure exploration and exploitation (PEE) and can be used in some cases where exploration is very costly or where the environment is very simple. However, in most real-world scenarios, PEE is not an optimal approach.</p>
<p>The problem with PEE is that the agent spends a lot of time exploring and collecting data, but not enough time exploiting that data to improve its policy. This can lead to slow learning and poor performance, especially in complex environments where there are many possible actions and states.</p>
<p>In contrast, most RL algorithms use a balance between exploration and exploitation, where the agent takes actions that are likely to yield high rewards based on its current policy while also occasionally exploring new actions or states. This allows the agent to learn quickly while still exploring new possibilities, leading to faster learning and better performance.</p>
<p>Furthermore, in many RL problems, the environment is dynamic and can change over time. In such cases, it is important for the agent to continuously explore and adapt to changes in the environment to maintain optimal performance. This requires a balance between exploration and exploitation, as well as the ability to update the policy based on new data and experiences.</p>
<p>In summary, while PEE can be a useful approach in some cases, a balanced approach between exploration and exploitation is generally more effective for most RL problems.</p>
<p><strong>为社么discount factor</strong></p>
<p>unstable env, noise in reward, </p>
<p><strong>为什么神经网络代替q表，那部分要用神经网络学习的不能表征的“规律”是什么？</strong></p>
<p>如果q表很大，就很难搞，为啥，那就建一个大的q表呗</p>
<p><strong>策略和价值的本质区别是什么，是不是一样的，那个策略更新跟argmax到底是不是一样的</strong></p>
<p>后面我可以i自己和环境玩，但是先按照教程完整拼一遍，</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://magiclucky1996.github.io/2023/04/25/insights/" data-id="clgw24ion0002yc9f8mcx3iab" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-都柏林租房攻略-狠人版" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/04/25/%E9%83%BD%E6%9F%8F%E6%9E%97%E7%A7%9F%E6%88%BF%E6%94%BB%E7%95%A5-%E7%8B%A0%E4%BA%BA%E7%89%88/" class="article-date">
  <time class="dt-published" datetime="2023-04-25T07:39:27.623Z" itemprop="datePublished">2023-04-25</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="都柏林租房攻略-狠人版"><a href="#都柏林租房攻略-狠人版" class="headerlink" title="都柏林租房攻略-狠人版"></a>都柏林租房攻略-狠人版</h1><ol>
<li><p>首先选区</p>
<p>参考这篇文章：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/112493998">https://zhuanlan.zhihu.com/p/112493998</a></p>
<p><img src="https://raw.githubusercontent.com/magiclucky1996/picgo/main/mapa-dublin-660x479.png" alt="img"></p>
</li>
</ol>
<p>理想居住区：2 4 6 6w 13 14 16 18</p>
<p>还行的居住区：1 3 5 7 12 15 17 20</p>
<p>从2 4 6 6w 13 14 16 18 中排除掉交通时间过远的</p>
<ul>
<li>打开hosting power <a target="_blank" rel="noopener" href="https://hostingpower.ie/">https://hostingpower.ie/</a></li>
</ul>
<p><img src="https://raw.githubusercontent.com/magiclucky1996/picgo/main/image-20230421113427078.png" alt="image-20230421113427078"></p>
<ul>
<li>选择area, 输入刚刚筛选出的区域结果</li>
</ul>
<p><img src="https://raw.githubusercontent.com/magiclucky1996/picgo/main/image-20230421113539429.png" alt="image-20230421113539429"></p>
<ul>
<li><p>选择max rent 点击apply</p>
</li>
<li><p>得到一系列搜索结果后，选择自己喜欢的房子</p>
</li>
<li><p>点进去根据界面提供的关键信息google search 房东的联系方式</p>
<ul>
<li>name</li>
<li>location</li>
<li>and so on</li>
<li>检索示范：”name” + ”location“ + site: airbnb.com</li>
</ul>
</li>
<li><p>自行联系房东签订合同等，可以省去hostingpower中介费890欧</p>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://magiclucky1996.github.io/2023/04/25/%E9%83%BD%E6%9F%8F%E6%9E%97%E7%A7%9F%E6%88%BF%E6%94%BB%E7%95%A5-%E7%8B%A0%E4%BA%BA%E7%89%88/" data-id="clgw24ioo0003yc9f3oa462wn" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-play with gym env" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/04/25/play%20with%20gym%20env/" class="article-date">
  <time class="dt-published" datetime="2023-04-25T07:39:27.623Z" itemprop="datePublished">2023-04-25</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="play-with-gym-env"><a href="#play-with-gym-env" class="headerlink" title="play with gym env"></a>play with gym env</h1><h2 id="env1-cart-pole"><a href="#env1-cart-pole" class="headerlink" title="env1: cart pole"></a>env1: cart pole</h2><p>control + pid: <a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_44562141/article/details/119700574">https://blog.csdn.net/weixin_44562141/article/details/119700574</a></p>
<p>document of gym <a target="_blank" rel="noopener" href="https://www.gymlibrary.dev/environments/classic_control/cart_pole/">https://www.gymlibrary.dev/environments/classic_control/cart_pole/</a></p>
<p>driving test <a target="_blank" rel="noopener" href="http://www.theory-tester.com/questions/358">http://www.theory-tester.com/questions/358</a></p>
<ul>
<li>state space:</li>
</ul>
<p>position</p>
<p>velocity</p>
<p>angle</p>
<p>angular velocity</p>
<ul>
<li><p>first understand problem, then understand reinforcement learning, u must understand the env, then you know why their study is like that, try to be a good teacher</p>
</li>
<li><p>for spare time, can play , for working time, only do things creating value to this project.</p>
<ul>
<li>first look for mappo implementation, then try doing it by myself</li>
</ul>
</li>
<li><p>if we want to control it with pid,</p>
</li>
<li><p>in this env, u are just study “action 要和夹角反着”+ 夹角和几个输入数据的关系，一部分是先验只是可以给的，所以我先原始地学习一下，再把state加工一下加进去，再试试一下把控制的东西加进去，对，我得先有想法，再实验，再读文献，再自己思考，再实验。我希望按照自己的想法来，这样我会沉迷于探索。我希望一直自己保有一些探索的时间，最后发现科研的乐趣。</p>
</li>
</ul>
<h2 id="frozen-lake"><a href="#frozen-lake" class="headerlink" title="frozen lake"></a>frozen lake</h2><p><a target="_blank" rel="noopener" href="https://colab.research.google.com/github/huggingface/deep-rl-class/blob/master/notebooks/unit2/unit2.ipynb#scrollTo=Y1tWn0tycWZ1">https://colab.research.google.com/github/huggingface/deep-rl-class/blob/master/notebooks/unit2/unit2.ipynb#scrollTo=Y1tWn0tycWZ1</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">qtable = np.zeros(state_space, action_space)</span><br><span class="line">action = argmax(qtable[state][:])</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Training parameters</span></span><br><span class="line">n_training_episodes = <span class="number">10000</span>  <span class="comment"># Total training episodes</span></span><br><span class="line">learning_rate = <span class="number">0.7</span>          <span class="comment"># Learning rate(这个不是梯度下降的learning rate,是td error的learning rate </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Evaluation parameters</span></span><br><span class="line">n_eval_episodes = <span class="number">100</span>        <span class="comment"># Total number of test episodes</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Environment parameters</span></span><br><span class="line">env_id = <span class="string">&quot;FrozenLake-v1&quot;</span>     <span class="comment"># Name of the environment</span></span><br><span class="line">max_steps = <span class="number">99</span>               <span class="comment"># Max steps per episode（防止回合死循环）</span></span><br><span class="line">gamma = <span class="number">0.95</span>                 <span class="comment"># Discounting rate （value的discounting）</span></span><br><span class="line">eval_seed = []               <span class="comment"># The evaluation seed of the environment</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Exploration parameters （刚开始探索大，后来探索小）</span></span><br><span class="line">max_epsilon = <span class="number">1.0</span>             <span class="comment"># Exploration probability at start</span></span><br><span class="line">min_epsilon = <span class="number">0.05</span>            <span class="comment"># Minimum exploration probability </span></span><br><span class="line">decay_rate = <span class="number">0.0005</span>            <span class="comment"># Exponential decay rate for exploration prob</span></span><br></pre></td></tr></table></figure>





<h2 id="env2-lunar"><a href="#env2-lunar" class="headerlink" title="env2 lunar"></a>env2 lunar</h2><p>安装</p>
<p>pip install box2d-py</p>
<h2 id="env3-taxi"><a href="#env3-taxi" class="headerlink" title="env3 taxi"></a>env3 taxi</h2><p><a target="_blank" rel="noopener" href="https://huggingface.co/learn/deep-rl-course/unit3/introduction?fw=pt">https://huggingface.co/learn/deep-rl-course/unit3/introduction?fw=pt</a></p>
<p>q leearning </p>
<p> 一句话概括：用r更新q值，轨迹的探索（也许可以根据特性选择走不同的轨迹，在探索的时候有偏好地探索，不是说增加exploit可以增加对有效区域的探索吗，更多的探索高价值动作转换到的轨迹上？，但是你怎么就知道那个东西就是个高价值呢）</p>
<p><img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/Q-learning-2.jpg" alt="Q-learning"></p>
<p><a target="_blank" rel="noopener" href="https://huggingface.co/learn/deep-rl-course/unit2/q-learning-example?fw=pt">https://huggingface.co/learn/deep-rl-course/unit2/q-learning-example?fw=pt</a></p>
<p>read this carefully</p>
<p>what if we don’t gradually improve the exploit?</p>
<p>u just explore and update the value, 因为如果它确实是最优value，你就可以直接选它，如果不是，你就陷入局部最优解，因此这其实是一个信任度的问题：“对它有多大可能是最优解的信任度”，我可以调整信任度，</p>
<p>什么情况下我确认在这个s take这个a是最优的，那就是终止状态向后回溯，但是对于状态很多的case呢？</p>
<p>之前我在玩cartpole时候，我的想法是把控制融合进去，探索</p>
<p>我想找一个可以可视化q表进化的程序跑一跑</p>
<p>我想今天把抱脸虫的教程结束掉</p>
<p>There are several powerful tools available for conducting reinforcement learning experiments. Here are a few popular ones:</p>
<ol>
<li>OpenAI Gym: OpenAI Gym is a popular toolkit for developing and comparing reinforcement learning algorithms. It provides a variety of environments, including classic control problems and Atari games.</li>
<li>TensorFlow Agents: TensorFlow Agents is an open-source library that provides a collection of reinforcement learning algorithms built on top of TensorFlow. It provides a simple API for experimenting with different algorithms and environments.</li>
<li>PyTorch RL: PyTorch RL is another open-source library that provides</li>
<li>RL</li>
<li>Stable Baselines: Stable Baselines is another open-source library that provides a collection of reinforcement learning algorithms. It includes support for a variety of environments and provides a simple API for training and evaluating agents.</li>
</ol>
<p>Ultimately, the choice of tool will depend on your specific needs and preferences. It is a good idea to experiment with several tools and choose the one that works best for your particular use case.</p>
<h1 id="Hyperparameter-tuning-with-Optuna"><a href="#Hyperparameter-tuning-with-Optuna" class="headerlink" title="Hyperparameter tuning with Optuna"></a>Hyperparameter tuning with Optuna</h1><p><a target="_blank" rel="noopener" href="https://colab.research.google.com/github/araffin/tools-for-robotic-rl-icra2022/blob/main/notebooks/optuna_lab.ipynb#scrollTo=hyyN-2qyK_T2">https://colab.research.google.com/github/araffin/tools-for-robotic-rl-icra2022/blob/main/notebooks/optuna_lab.ipynb#scrollTo=hyyN-2qyK_T2</a></p>
<p>能用库就用库，看看我们真正要做的是什么，其它需要解决的部分用最简单的方法解决，重要的是可视化rl，理解每一步在干嘛，的到一些insights</p>
<p>我只有两天的时间了，我要用半天的时间把这个教程过掉</p>
<p>用半天的时间把我想搞明白的事情全部搞明白，或者今天直接在家办工了</p>
<p>4. </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://magiclucky1996.github.io/2023/04/25/play%20with%20gym%20env/" data-id="clgw24ioo0004yc9fc4nu6ekv" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-hello-world" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/04/11/hello-world/" class="article-date">
  <time class="dt-published" datetime="2023-04-11T11:45:28.964Z" itemprop="datePublished">2023-04-11</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/04/11/hello-world/">Hello World</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://magiclucky1996.github.io/2023/04/11/hello-world/" data-id="clgc7f4xc0000jaot0d8thucp" data-title="Hello World" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/04/">April 2023</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2023/04/25/dublin%E9%80%82%E5%90%88%E8%BF%9C%E7%A8%8B%E5%8A%9E%E5%85%AC%E7%9A%84%E5%9C%B0%E7%82%B9%E5%90%88%E9%9B%86/">(no title)</a>
          </li>
        
          <li>
            <a href="/2023/04/25/incoporate%20%20mappo%20with%20sumo/">(no title)</a>
          </li>
        
          <li>
            <a href="/2023/04/25/MARL%20implementation/">(no title)</a>
          </li>
        
          <li>
            <a href="/2023/04/25/insights/">(no title)</a>
          </li>
        
          <li>
            <a href="/2023/04/25/%E9%83%BD%E6%9F%8F%E6%9E%97%E7%A7%9F%E6%88%BF%E6%94%BB%E7%95%A5-%E7%8B%A0%E4%BA%BA%E7%89%88/">(no title)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2023 tianxiang<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>